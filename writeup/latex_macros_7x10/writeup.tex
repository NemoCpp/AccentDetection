%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                                                                                                                                                                                                           %%%
%%%   NOTE!!!!!!!!!!!!!!! If you get some compile error that refers to a runaway argument, just remove writeup.aux and compile again!  %%%
%%%                                                                                                                                                                                                            %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%                                             %%%%%%%%
%%%%%%%%          The commands I        %%%%%%%%
%%%%%%%%      remembered to keep      %%%%%%%%
%%%%%%%%               track of                  %%%%%%%%
%%%%%%%%                                             %%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% HCopy  -A  -D  -C analysis.conf  -S testlist.txt

% HInit -A -T 1 -S hinit_trainlist.txt -M model/hmm0 -H model/proto/hmm_security_english -l security_english -L data/train/lab security_english

% HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm1 -H model/hmm0/hmm_security_english -l security_english -L data/train/lab security_english

% HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm4 -H model/hmm3/hmm_security_english -l security_english -L data/train/lab security_english

% HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm1 -H model/hmm0/hmm_security_spanish -l security_spanish -L data/train/lab security_spanish

% HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm2 -H model/hmm1/hmm_security_spanish -l security_spanish -L data/train/lab security_spanish

% HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm3 -H model/hmm2/hmm_security_spanish -l security_spanish -L data/train/lab security_spanish

% HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm4 -H model/hmm3/hmm_security_spanish -l security_spanish -L data/train/lab security_spanish

% HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm1 -H model/hmm0/hmm_sil -l sil -L data/train/lab sil

% HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm2 -H model/hmm1/hmm_sil -l sil -L data/train/lab sil

% HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm3 -H model/hmm2/hmm_sil -l sil -L data/train/lab sil

% HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm4 -H model/hmm3/hmm_sil -l sil -L data/train/lab sil

% HVite -A -D -T 1  -H hmmsdef.mmf  -i reco.mlf  -w net.slf  dict.txt  hmmlist.txt  data/test/mfcc/input.mfcc

%%%%%%%%%%%%%%
%% Run LaTeX on this file several times to get Table of Contents,
%% cross-references, and citations.

%%%%%%%%%%%%%
% 7x10
\documentclass{wileySev}

\usepackage{graphicx}

\usepackage{hyperref}
\usepackage{color}% http://ctan.org/pkg/{hyperref,xcolor}

\definecolor{greenish}{RGB}{64, 177, 98}
\definecolor{orangish}{RGB}{253, 178, 71}
\definecolor{dark_greenish}{RGB}{10, 100, 37}
\definecolor{bluish}{RGB}{39, 64, 112}

\hypersetup{
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=bluish,          % color of internal links (change box color with linkbordercolor)
    citecolor=orangish,        % color of links to bibliography
    urlcolor=dark_greenish           % color of external links
}

% For PostScript text
\usepackage{w-bookps}

\setcounter{secnumdepth}{3}

\setcounter{tocdepth}{2}

\newcommand{\VT}[1]{\ensuremath{{V_{T#1}}}}

\newbox\sectsavebox
\setbox\sectsavebox=\hbox{\boldmath\VT{xyz}}

\usepackage{multicol}
\newenvironment{myitemize}{%
\begin{itemize}
\begin{multicols}{2}
}{%
\end{multicols}
\end{itemize}
}

\begin{document}

\offprintinfo{Probabilistic Accent Detection Using HMMs}{Calhoun, Parker, Vaslas, and Vera}

\booktitle{Spoken Language Accent Detection}
\subtitle{Probabilistic Accent Detection Using Hidden Markov Models}

\authors{Tr\'e Calhoun\\
La Vesha Parker\\
Andrew Vaslas\\
Nicolas Vera\\
\affil{Cornell University}
}

\titlepage
\tableofcontents


\begin{preface}
All information presented within this document represents our exploration of the HTK software. We make no guarantee of things things things

\end{preface}

\begin{introduction}
% Discuss our motivation, etc.
This is the introduction.
This is the introduction.
This is the introduction.
This is the introduction.
This is the introduction.
This is the introduction.


\end{introduction}


\part[HTK Software Suite]
{Hidden Markov Model\\Toolkit Software Suite}

\chapter{Installation of HTK Software}
\section{General Installation information}
The website for HTK can be found \href{http://htk.eng.cam.ac.uk/}{here}. The HTK developers require that you \href{http://htk.eng.cam.ac.uk/register.shtml}{register for a username and password} through their site before downloading their software. After registering, visit the \href{http://htk.eng.cam.ac.uk/download.shtml}{downloads} page and download the HTK source code (available as a tarball). It is also useful to download the HTKBook as a PDF (available on the downloads page below the software). If you do not wish to download the book, you can \href{http://htk.eng.cam.ac.uk/docs/docs.shtml}{view the book online} after registering.

\section{Mac OS X}
In order to install HTK for Mac OS X, you first need to make sure that you have Xcode developer tools and X11 installed.

What follows are the installation instructions taken \textit{directly from the README in the root directory of the unziped htk/ directory}, save a bit of formatting. We do not claim this work, and repeat it here only for convenience.\\

\subsubsection{Compiling \& Installing HTK under UNIX/Linux, OS X or Cygwin}~\\

After unpacking the sources, cd to the htk directory.\\

There are now two ways to install HTK, the "traditional" and the
"new".  Up to now HTK has always installed its tools as they were
built, and installed them to a directory such as "bin.linux" so that
binaries for different architectures can be installed in a home
directory say.  If you want to install in this way, please add the
option "--enable-trad-htk" when you run configure.\\

The "new" method installs by default into /usr/local/bin (equivalent
to a configure option of "--prefix=/usr/local").\\

\begin{enumerate}
	\item decide which of the above methods you wish to use
	\item cd to htk, then run ./configure (with appropriate options, run "./configure --help" if unsure).
   If you don't want to build the programs in HLMTools add the
   --disable-hlmtools option.
	\item make all
	\item make install
\end{enumerate}

Running "make install" will install them.  This step may need to be
done as root, if you are not installing them in your home directory.\\

Notes for particular Unix variants:\\
Solaris: if "make" isn't installed you may need to add /opt/sfw/bin
and /usr/ccs/bin to your path and run "./configure MAKE=gmake" with
any other options you require.  Then run "gmake" instead of "make",
alternatively you can create a symbolic link called "make" somewhere
it your path to /opt/sfw/bin/gmake

\section{Windows}
% Tre and Nicolas: I remember you two had to install additional software while you tried to get HTK to work. When you get it fully installed on your machines, please list all the additional software you used
% And also explain how/where to get it! (links like those I put in "General Installation Information" section would be useful here)
Once again, what follows are the installation instructions taken \textit{directly from the README in the root directory of the unziped htk/ directory}, save a bit of formatting. We do not claim this work, and repeat it here only for convenience.\\
\subsubsection{Compiling \& Installing HTK under Windows}~\\

\textbf{Prerequisites:}
\begin{itemize}
	\item HTK has been verified to compile using Microsoft Visual Studio.
	\item For testing, you will require a Perl interpreter such as ActivePerl. 
	\item You will need a tool such as 7-zip or winzip (commercial) for unpacking the HTK source code archive.
	\item It it is helpful if you have some familiarity with using the DOS command line interface, as you will need to interact with it in order to compile, install and run HTK.
	\item Ensure that your PATH contains:
		\begin{verbatim}
		C:\Program Files\Microsoft Visual Studio .NET 2003\Vc7\bin
		\end{verbatim}
		Or if you are using older versions:
		\begin{verbatim}
		C:\Program Files\Microsoft Visual Studio\VC98\bin
		\end{verbatim}
\end{itemize}


\textbf{Compilation:}
\begin{enumerate}
\item Unpack the HTK sources using 7-zip.
\item Open a DOS command window: Click Start, select Run type cmd at the prompt and click OK.
\item cd into the directory in which you unpacked the sources.
\item cd into the htk directory. Type:
\begin{verbatim}
      cd htk
\end{verbatim}
\end{enumerate}

   5. Create a directory for the library and tools. Type:

\begin{verbatim}
      mkdir bin.win32
\end{verbatim}

   6. Run VCVARS32 (it should be in your path, see prerequisites above)
   7. Build the HTK Library, which provides the common functionality
      used by the HTK Tools. Enter the following commands:

\begin{verbatim}
          cd HTKLib
          nmake /f htk_htklib_nt.mkf all
          cd ..
\end{verbatim}

   8. Build the HTK Tools
\begin{verbatim}
          cd HTKTools
          nmake /f htk_htktools_nt.mkf all
          cd ..
          cd HLMLib
          nmake /f htk_hlmlib_nt.mkf all
          cd ..
          cd HLMTools
          nmake /f htk_hlmtools_nt.mkf all
          cd ..
\end{verbatim}

\textbf{Installation:}\\
The HTK tools have now been built and are in the bin.win32
directory. You should add this directory to your PATH, so that you can
run them easily from the command line in future.

\chapter{Training and Testing Corpus Acquisition}
\prologue{Everyone has the right to life, liberty and security of person.}
{United Nations' Declaration of Human Rights \cite{UNDHR}}
\section{The Nature of Our Data}
\section{The Online Speech/Corpora Archive and Analysis Resource}
Northwestern University's Online Speech/Corpora Archive and Analysis Resource (\href{https://oscaar.ci.northwestern.edu/}{OSCAAR}) is a collection of speech recordings from speakers with different backgrounds, assembled from various datasets.

To request access to the data available through OSCAAR, you can \href{https://oscaar.ci.northwestern.edu/requests.php}{submit a request for access} to the OSCAAR collections. In our experience, requests are handled within 24-48 hours after being sent.

The dataset that we found most appropriate for our goal of accent detection and classification is the \href{http://groups.linguistics.northwestern.edu/speech_comm_group/allsstar/}{ALLSTAR} dataset from the Speech and Communication Research Group at Northwestern University. The dataset is massive, and we found that a subset of samples fit our needs well.

Part of the dataset features recording of talkers from different backgrounds saying 20 sentences pulled from the Declaration of Human Rights in English. For our proof of concept, we used a subset of that portion of speakers reading Article 3 from the DHR: "Everyone has the right to life liberty and security of person." That subset of the data featured 
talkers with the following native tongues:
\begin{myitemize}
\item Brazilian Portuguese
\item English
\item French
\item German
\item Hebrew
\item Hindi
\item Japanese
\item Korean
\item Mandarin Chinese
\item Persian (Farsi)
\item Russian
\item Spanish
\item Turkish
\item Vietnamese
\end{myitemize}

\chapter{Training Corpus with HTK}



\section{Record or Input Sound Files}
Having acquired the sound clips from OSCAAR, we needed to select two distinct native tongues. Native English and native Spanish speakers were selected since these subsets had what we felt was a sufficient amount of data for the purposes of this project; some of the others only had a few samples and having more data is conducive to the training of the HMM.

Some of our data was set aside for testing. In data/train/ and data/test/, the .wav audio clips themselves are stored in wav/ and their respective .mfcc and .lab files were stored in mfcc/ and lab/. The free audio editor Audacity was used to crop the .wav files so that only the word "security" could be heard. Audacity allowed us to generate silent audio surrounding the cropped clips.

\section{Labeling the Sound Files}
HLab allowed us to label the boundaries between words and the silence around them in each .wav file. With a beginning silence, the spoken word, and the ending silence labeled, a .lab file for each clip was created. The .lab files are merely text files marking the start and end sample times for each of these labeled sections:

\begin{verbatim}
data/train/lab/english_f1_security.lab
20408 4239909 sil
4342857 9941497 security_english
9982766 13996825 sil
\end{verbatim}

\chapter{Coding the Data}

\section{Mel Frequency Cepstral Coefficients}
Here we describe what a MFCC is and its usefulness to us.

\section{Obtaining .mfcc Files}
HLab also produces a .sig signal file upon opening the audio clip. Once saved, these files were converted into .mfcc files using HCopy. The .sig files themselves cannot be analyzed. The .mfcc files, which each contain a set of vector representations of the sound signal, can be analyzed. Each 25ms segment is represented by a vector of acoustical coefficients, which provides a description of that segment's spectral properties. HCopy required a configuration file to give values to its parameters:

\subsection{Configuration File}
\begin{verbatim}
#analysis.conf
SOURCEFORMAT = WAV    # Gives the format of the speech files
TARGETKIND = MFCC_0_D_A    # Identifier of the coefficients to use

# Unit = 0.1 micro-second :
WINDOWSIZE = 250000.0    # = 25 ms = length of a time frame
TARGETRATE = 100000.0    # = 10 ms = frame periodicity

NUMCEPS = 12     # Number of MFCC coeffs (here from c1 to c12)
USEHAMMING = T    # Use of Hamming function for windowing frames
PREEMCOEF = 0.97     # Pre-emphasis coefficient
NUMCHANS = 26     # Number of filterbank channels
CEPLIFTER = 22     # Length of cepstral liftering
\end{verbatim}

\subsection{The Creation of targetlist.txt}

The file trainlist.txt gives the name and directory of each waveform file and their respective target coefficient files:
\begin{verbatim}
data/train/wav/english_f1_security.wav data/train/mfcc/english_f1_security.mfcc
data/train/wav/english_f2_security.wav data/train/mfcc/english_f2_security.mfcc

(and so on)
\end{verbatim}

\section{Command Line Actions}
To execute this conversion, the following command was used:
\begin{verbatim}
HCopy -A -D -C analysis.conf -S trainlist.txt
\end{verbatim}

\chapter{Setting Parameters for the Hidden Markov Model}

\section{What is a Hidden Markov Model?}
A hidden Markov model (HMM) is a type of Markov model, which means future states depend only on the current state. Classically, the states in this model are classified as one of two types: observation and hidden states. This model states that the observation states are determined by the underlying hidden states; thus, the observations are inputs to the problem and the hidden states need to be discovered. There are two key types of probabilities that connect the states: emission probabilities, the probability of an observation state given a hidden state; and transition probabilities, the probability of a hidden state given a previous hidden state (the Markov property). Given a number of hidden states and a set of observations, we can learn the probabilities to maximize the collective probability of each observation. Given the states, the transition and emission probabilities, and a sound, we can use a HMM to determine the probability of the sound under the model.

\section{HMMs and Accent Detection}
\subsection{Overview}
An HMM is a good model to use for accent detection because a discretized sound directly maps to the observation states as inputs to the model. These observed sounds segments are dependent on the speaker's accent, which means there must be underlying hidden states that model the likelihood of the sound segment produced given the accent (the emission probability). It is reasonable to believe that transition probabilities exist between the hidden states, as accents may dictate that certain sounds should have a high or low likelihood of following another sound. We use HMMs by defining an HMM for each of the acoustical events (English, Spanish, and silence). Then, given a sound and its correct event type, we want to train each HMM (i.e. determine the transition and emission probabilities) so that the corresponding HMM with the same event type returns a probability that is much higher than the the probabilities that the others return. Finally, given a sound, we can predict its acoustical event type using the one-vs-all methodology by calculating which HMM returns the highest probability. More details about the process are below.

\subsection{HMM Definition}
To implement an HMM, we must first define its structure. We define each HMM as a continuous density HMM with n states in total, 2 of which are non-emitting (HTK reserves the first and last states for implementation reasons). Because each observation (a 25ms segment) is represented by a vector of acoustical coefficients, our emission probability must actually be a vector of sub-emission probabilities corresponding to each acoustical coefficient. As each acoustical coefficient is a floating-point number, we describe the probability of the coefficient by using a Gaussian distribution. Gaussian distributions are defined by a mean and variance; thus, we can simply describe the overall emission of each hidden state by a vector of means and a vector of variances. (The cardinality of the mean and variance vectors is equal to the number of acoustical coefficients.) We also define a nxn transition matrix that defines the transition probabilities between hidden states. 

We define "prototype" HMM description files for each of the acoustical events that contains this information; each file is equivalent, save for different names. These files are prototypes, as they describe the structure of the HMM, but the values (mean and variance vectors and transition probabilities) are relatively arbitrary, and will be corrected during initialization and training (described below). Thus, we set each mean as a vector of zeros, each variance as a vector of ones, and the transition probabilities are established so that the sum of transitioning from state i to any state is equal to 1 (except for the final, nth state, which is accepting, so all of its transition probabilities equal 0). Note that setting any index of this transition matrix to 0 means that it will always be 0, even after initialization and training. We use n=6 states, and mean and variance vector sizes of 39, as there are 39 MFCC acoustical coefficients.
% TODO: Create and add this figure
Figure FILL shows our prototype HMM definition for the English accent. These prototypes are saved as "hmm\_security\_english", "hmm\_security\_spanish", and "hmm\_sil" for the corresponding sound type in a model/proto directory.

\subsection{Training}
Training is the process of estimating the parameters of the HMMs by using labelled sound examples. To start, we initialize each HMM with the HTK tool HInit, which time-aligns the training data with a Viterbi algorithm. Doing this estimates initial parameters (mean and variance vectors and transition probabilities) based of off the prototype HMM description file for each initial HMM. Then we train the models by using the HTK tool HRest on each HMM until convergence. HRest uses Baum-Welch parameter re-estimation to perform one re-estimation iteration on an input HMM, producing a new HMM. Starting from the initialized HMMs, we iteratively use HRest until its change measure does not decrease (i.e. until it converges). We performed one iteration on the Silence HMM and three iterations on the English and Spanish HMMs. 

This completes the training of the HMMs; we now have models such that if we input a single acoustical event (a sound of silence, a sound of "security" in an English accent, or a sound of "security" in Spanish accent), we can predict which event type it is with some accuracy. More detail about HInit and HRest can be found in the HTKBook.

\section{Input Parameters to HMMs} 
%TODO
Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum


\section{Command Line Actions}
The following command initializes a HMM with HInit:
\begin{verbatim}
HInit -A -D ?T 1 -S trainlist.txt -M model/hmm0 -H model/proto/hmmfile -l label -L label_dir nameofhmm
\end{verbatim}
Here: hmmfile is contained in {hmm\_security\_english, hmm\_security\_spanish, hmm\_sil}; label is in {english, spanish, sil}; label\_dir is data/train/lab/; nameofhmm is in {english, spanish, sil}.
This must be repeated for each model {english, spanish, sil}

The following command performs one re-estimation iteration with HRest:
\begin{verbatim}
HRest -A -D -T 1 -S trainlist.txt -M model/hmmi -H vFloors -H model/hmmi-1/hmmfile -l label -L label_dir nameofhmm
\end{verbatim}
Here: model/hmmi refers to the output directory, which indicates the index of the current iteration i (1,2,3,...); hmmfile is contained in {hmm\_security\_english, hmm\_security\_spanish, hmm\_sil}, and its parent directory model/
hmmi-1 indicates the index of the last iteration (0,1,2,...); label is in {english, spanish, sil}; label\_dir is data/train/lab/; nameofhmm is in {english, spanish, sil}.
This procedure has to be repeated several times for each HMM to train.

\chapter{Defining the Grammar of Your Network}
\section{What does that even mean}
\section{Define your Grammar}
\section{Define your Dictionary}
\section{Generating the Network}
\section{Command Line Actions}

\chapter{Testing with New Samples}
Corresponds to the Recognition chapter (Moreau ch. 7)
\section{Command Line Actions}

\part{Error Handling, Software Used and Resources}

\appendix{Error Handling}
\markboth{A short guide to understanding and handling errors}{A short guide to understanding and handling errors}
Errors that crop up when using HTK can seem confusing initially, but they can be debugged with a bit of critical thinking and some hints from outside sources. We found the following sources helpful when debugging:
\begin{itemize}
\item \href{http://www.ling.ohio-state.edu/~bromberg/htk_problems.html}{Ohio State University: Understanding HTK Error Messages}
\item \href{http://www.ee.columbia.edu/~dpwe/LabROSA/doc/HTKBook21/node256.html}{Columbia University: Summary of Errors by Tool and Module}
\end{itemize}

During our time with the HTK software, we experienced a subset of the error codes that we could experience. If you encounter theses error codes yourself, there is no guarantee that our error resolutions will also work for you, but hopefully they will help with debugging seeing 


\appendix{Software Used}
We have provided information about our use of various software (particularly the various toolkits available through the HTK software) throughout this guide, so we will merely provide a summary of what 
\begin{enumerate}
	\item Audacity: Useful for processing audio files. Used to splice .wav files to extract specific words from .wav files. Also useful for generating segments of silence to make differentiating between SIL labels and spoken words easier.
	\item HTK: Maybe even list each of the things we used under HTK \& why, i.e. HSLab for labeling, HParse for whatever
		\begin{enumerate}
			\item \textbf{HSLab}\\
				Provides a graphical user interface for the labeling of sound files. Accepts waveform files (i.e. .sig files recorded directly in HSLab and .wav files that users can pre-record). The default expected filetype is .sig, so if you plan to use a different file type, be sure to include a configuration file (i.e. our analysis.conf) that specifies the \textsc{source format}.\\
				
				Sample command line invocation: 
				\begin{verbatim}
				HSLab -C <config_file.conf> <sound_file.ext>
				\end{verbatim}
			\item \textbf{HCopy}\\
				The primary use of HCopy is to copy and manipulate speech files. Another use for HCopy (and our particular use here) is to convert waveform data to Mel Frequency Cepstral Coefficients.
				HCopy accepts pairs of source specifications for .lab files and destination specifications for the .mfcc files that HCopy will generate for each of the .lab files.
				
				Sample command line invocation: 
				\begin{verbatim}
				HCopy -C <config_file.conf>  -S testlist.txt
				\end{verbatim}
			\item \textbf{Hinit}\\
				Sample command line invocation: 
				\begin{verbatim}
				HInit -A -T 1 -S hinit_trainlist.txt -M model/hmm0 -H model/proto/hmm_security_english -l security_english -L data/train/lab security_english
				\end{verbatim}
			\item \textbf{HRest}\\
				Sample command line invocation: 
				\begin{verbatim}
				HRest -A -T 1 -S hinit_trainlist.txt -M model/hmm1 -H model/hmm0/hmm_security_english -l security_english -L data/train/lab security_english
				\end{verbatim}
			\item \textbf{HParse}\\
				Sample command line invocation: 
				\begin{verbatim}
				HParse -A -T 1   def/gram.txt   net.slf
				\end{verbatim}
			\item \textbf{HVite}\\
				Sample command line invocation: 
				\begin{verbatim}
				HVite -A -D -T 1  -H hmmsdef.mmf  -i reco.mlf  -w net.slf
				\end{verbatim}
		\end{enumerate}
		Global useful flags:
		\begin{enumerate}
			\item f
		\end{enumerate}
\end{enumerate}


\appendix{References}
% Just contains a sample reference for HMMs on Wikipedia. 
\begin{references}{3.}
\bibitem{link_used_elsewhere}Random People,
\href{http://en.wikipedia.org/wiki/Hidden_Markov_model}{``Hidden Markov Model,''}(2014).

% Vesha note for self: fix these
\bibitem{link_used_elsewhere}Random People,
\href{http://www.labunix.uqam.ca/~boukadoum_m/DIC9315/Notes/Markov/HTK_basic_tutorial.pdf}{`HTK Basic Tutorial'}(2014).

\bibitem{link_used_elsewhere}Random People,
\href{http://www.voxforge.org/home/dev/acousticmodels/linux/create/htkjulius/tutorial/data-prep/step-5}{`HCopy Config File'}(2014).

                 
\bibitem{UNDHR}UN General Assembly,
		{\it Universal Declaration of Human Rights}, 10 December 1948, 217 A (III), available at: http://www.refworld.org/docid/3ae6b3712c.html 

\end{references}


\printindex


\end{document}

